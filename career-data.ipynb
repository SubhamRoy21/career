{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08677477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99fde64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\roysu\\OneDrive\\Desktop\\student data with career.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d99bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28be7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.drop(columns=['id','first_name','last_name','email','gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67053538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math_score</th>\n",
       "      <th>aptitude_score</th>\n",
       "      <th>science_score</th>\n",
       "      <th>logical_score</th>\n",
       "      <th>verbal_score</th>\n",
       "      <th>career_aspiration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>53</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "      <td>Lawyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>Doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>55</td>\n",
       "      <td>96</td>\n",
       "      <td>85</td>\n",
       "      <td>Government Officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>Finance officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>93</td>\n",
       "      <td>Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>82</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>100</td>\n",
       "      <td>Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>85</td>\n",
       "      <td>94</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "      <td>Lawyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>92</td>\n",
       "      <td>Artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>98</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>69</td>\n",
       "      <td>63</td>\n",
       "      <td>Stock Investor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     math_score  aptitude_score  science_score  logical_score  verbal_score  \\\n",
       "0            73              81             53             97            93   \n",
       "1            70              86             96             80            73   \n",
       "2            81              97             55             96            85   \n",
       "3           100              74             88             80            89   \n",
       "4            84              77             65             65            80   \n",
       "..          ...             ...            ...            ...           ...   \n",
       "280          92              88             76             69            93   \n",
       "281          82              95             96             89           100   \n",
       "282          85              94             83             77            76   \n",
       "283          82              85             75             76            92   \n",
       "284          98              77             94             69            63   \n",
       "\n",
       "      career_aspiration  \n",
       "0                Lawyer  \n",
       "1                Doctor  \n",
       "2    Government Officer  \n",
       "3          Data Analyst  \n",
       "4       Finance officer  \n",
       "..                  ...  \n",
       "280   Software Engineer  \n",
       "281           Scientist  \n",
       "282              Lawyer  \n",
       "283              Artist  \n",
       "284      Stock Investor  \n",
       "\n",
       "[285 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876ab4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "career_aspiration\n",
       "Software Engineer        51\n",
       "Business Owner           45\n",
       "Unknown                  28\n",
       "Banker                   22\n",
       "Accountant               19\n",
       "Lawyer                   17\n",
       "Doctor                   14\n",
       "Stock Investor           13\n",
       "Game Developer           10\n",
       "Artist                   10\n",
       "Construction Engineer     9\n",
       "Designer                  8\n",
       "Real Estate Developer     8\n",
       "Teacher                   6\n",
       "Government Officer        6\n",
       "Scientist                 6\n",
       "Writer                    3\n",
       "Ethical hacker            2\n",
       "Programmer                2\n",
       "Data Analyst              2\n",
       "ML Engineer               2\n",
       "Finance officer           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['career_aspiration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319a3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_aspiration_map={\n",
    "    'Lawyer':0,'Doctor':1,'Government Officer':2,'Artist':3,'Finance officer':4,\n",
    "    'Software Engineer':5,'Teacher':6,'Business Owner':7,'Scientist':8,\n",
    "    'Banker':9,'Writer':10,'Accountant':11,'Designer':12,'Construction Engineer':13,\n",
    "    'Game Developer':14,'Stock Investor':15,'Real Estate Developer':16,'Programmer':17,\n",
    "    'Ethical hacker':18,'ML Engineer':19,'Data Analyst':20,'Stock investor':21,'Unknown':22\n",
    "}\n",
    "df1['career_aspiration'] = df1['career_aspiration'].map(career_aspiration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c1ba58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       2\n",
       "3      20\n",
       "4       4\n",
       "       ..\n",
       "280     5\n",
       "281     8\n",
       "282     0\n",
       "283     3\n",
       "284    15\n",
       "Name: career_aspiration, Length: 285, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['career_aspiration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "712f7b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "career_aspiration\n",
      "5     51\n",
      "7     45\n",
      "22    28\n",
      "9     22\n",
      "11    19\n",
      "0     17\n",
      "1     14\n",
      "15    13\n",
      "14    10\n",
      "3     10\n",
      "13     9\n",
      "12     8\n",
      "16     8\n",
      "6      6\n",
      "2      6\n",
      "8      6\n",
      "10     3\n",
      "18     2\n",
      "17     2\n",
      "20     2\n",
      "19     2\n",
      "4      2\n",
      "Name: count, dtype: int64\n",
      "math_score        0\n",
      "aptitude_score    0\n",
      "science_score     0\n",
      "logical_score     0\n",
      "verbal_score      0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of classes\n",
    "print(y.value_counts())\n",
    "\n",
    "# Ensure X and y are properly aligned and have no missing values\n",
    "print(X.isnull().sum())\n",
    "print(y.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e54441d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "#adasyn = ADASYN()\n",
    "smote = SMOTE(k_neighbors=1,random_state=42)\n",
    "X=df1.drop('career_aspiration',axis=1)\n",
    "y=df1['career_aspiration']\n",
    "X_resampled,y_resampled=smote.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84967ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df1.drop(columns=['career_aspiration'],axis=1)\n",
    "y=df1['career_aspiration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b76518cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math_score</th>\n",
       "      <th>aptitude_score</th>\n",
       "      <th>science_score</th>\n",
       "      <th>logical_score</th>\n",
       "      <th>verbal_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>53</td>\n",
       "      <td>97</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>55</td>\n",
       "      <td>96</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>82</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>85</td>\n",
       "      <td>94</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>98</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>69</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     math_score  aptitude_score  science_score  logical_score  verbal_score\n",
       "0            73              81             53             97            93\n",
       "1            70              86             96             80            73\n",
       "2            81              97             55             96            85\n",
       "3           100              74             88             80            89\n",
       "4            84              77             65             65            80\n",
       "..          ...             ...            ...            ...           ...\n",
       "280          92              88             76             69            93\n",
       "281          82              95             96             89           100\n",
       "282          85              94             83             77            76\n",
       "283          82              85             75             76            92\n",
       "284          98              77             94             69            63\n",
       "\n",
       "[285 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8613852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       2\n",
       "3      20\n",
       "4       4\n",
       "       ..\n",
       "280     5\n",
       "281     8\n",
       "282     0\n",
       "283     3\n",
       "284    15\n",
       "Name: career_aspiration, Length: 285, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abb59ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f69c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler1=StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler1.fit_transform(X_train)\n",
    "X_test_scaled = scaler1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9763178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bc508ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    \"Logistic Regression\":LogisticRegression(),\n",
    "    \"Support Vector Classifier\":SVC(),\n",
    "    \"Random Forest Classifier\":RandomForestClassifier(),\n",
    "    \"KNeighborsClassifier\":KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\":DecisionTreeClassifier(),\n",
    "    \"GaussianNB\":GaussianNB(),\n",
    "    \"AdaBoostClassifier\":AdaBoostClassifier(),\n",
    "    \"GradientBoostingClassifier\":GradientBoostingClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29dde3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: Logistic Regression\n",
      "0.38596491228070173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.42      0.71      0.53        14\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.62      0.83      0.71        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "          11       0.50      0.25      0.33         4\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.17      0.14      0.15         7\n",
      "\n",
      "    accuracy                           0.39        57\n",
      "   macro avg       0.11      0.12      0.11        57\n",
      "weighted avg       0.29      0.39      0.32        57\n",
      "\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "0.43859649122807015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.41      0.79      0.54        14\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.69      0.75      0.72        12\n",
      "           9       0.29      0.67      0.40         3\n",
      "          11       1.00      0.50      0.67         4\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.33      0.14      0.20         7\n",
      "\n",
      "    accuracy                           0.44        57\n",
      "   macro avg       0.17      0.18      0.16        57\n",
      "weighted avg       0.37      0.44      0.38        57\n",
      "\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "0.3508771929824561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.47      0.64      0.55        14\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.67      0.67      0.67        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "          11       1.00      0.50      0.67         4\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.33      0.14      0.20         7\n",
      "\n",
      "    accuracy                           0.35        57\n",
      "   macro avg       0.15      0.11      0.12        57\n",
      "weighted avg       0.37      0.35      0.35        57\n",
      "\n",
      "==================================================\n",
      "Model: KNeighborsClassifier\n",
      "0.17543859649122806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.23      0.21      0.22        14\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.64      0.58      0.61        12\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         3\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.18        57\n",
      "   macro avg       0.05      0.04      0.05        57\n",
      "weighted avg       0.19      0.18      0.18        57\n",
      "\n",
      "==================================================\n",
      "Model: DecisionTreeClassifier\n",
      "0.19298245614035087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.22      0.14      0.17        14\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.70      0.58      0.64        12\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.33      0.25      0.29         4\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.25      0.14      0.18         7\n",
      "\n",
      "    accuracy                           0.19        57\n",
      "   macro avg       0.08      0.06      0.06        57\n",
      "weighted avg       0.26      0.19      0.22        57\n",
      "\n",
      "==================================================\n",
      "Model: GaussianNB\n",
      "0.3333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.43      0.64      0.51        14\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.64      0.75      0.69        12\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         3\n",
      "          11       1.00      0.25      0.40         4\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.33        57\n",
      "   macro avg       0.12      0.10      0.09        57\n",
      "weighted avg       0.31      0.33      0.30        57\n",
      "\n",
      "==================================================\n",
      "Model: AdaBoostClassifier\n",
      "0.3157894736842105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.27      1.00      0.42        14\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.80      0.33      0.47        12\n",
      "           9       0.00      0.00      0.00         3\n",
      "          11       0.00      0.00      0.00         4\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.32        57\n",
      "   macro avg       0.07      0.09      0.06        57\n",
      "weighted avg       0.23      0.32      0.20        57\n",
      "\n",
      "==================================================\n",
      "Model: GradientBoostingClassifier\n",
      "0.3508771929824561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.42      0.57      0.48        14\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.78      0.58      0.67        12\n",
      "           9       0.33      0.33      0.33         3\n",
      "          11       0.67      0.50      0.57         4\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.40      0.29      0.33         7\n",
      "\n",
      "    accuracy                           0.35        57\n",
      "   macro avg       0.15      0.13      0.14        57\n",
      "weighted avg       0.38      0.35      0.36        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name,model in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(\"Model:\",name)\n",
    "    model.fit(X_train_scaled,y_train)\n",
    "    y_pred=model.predict(X_test_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    classification_rep=classification_report(y_test,y_pred)\n",
    "#     conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    print(accuracy)\n",
    "    print(classification_rep)\n",
    "#     print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3263684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43859649122807015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.41      0.79      0.54        14\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.69      0.75      0.72        12\n",
      "           9       0.29      0.67      0.40         3\n",
      "          11       1.00      0.50      0.67         4\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.33      0.14      0.20         7\n",
      "\n",
      "    accuracy                           0.44        57\n",
      "   macro avg       0.17      0.18      0.16        57\n",
      "weighted avg       0.37      0.44      0.38        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1 = SVC(probability=True)\n",
    "model1.fit(X_train_scaled,y_train)\n",
    "y_pred=model1.predict(X_test_scaled)\n",
    "    \n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "classification_rep=classification_report(y_test,y_pred)\n",
    "#     conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "print(accuracy)\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7f4a1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math_score</th>\n",
       "      <th>aptitude_score</th>\n",
       "      <th>science_score</th>\n",
       "      <th>logical_score</th>\n",
       "      <th>verbal_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>88</td>\n",
       "      <td>71</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>94</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>97</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>99</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>97</td>\n",
       "      <td>92</td>\n",
       "      <td>79</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>91</td>\n",
       "      <td>98</td>\n",
       "      <td>76</td>\n",
       "      <td>65</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>92</td>\n",
       "      <td>77</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>57</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>71</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>96</td>\n",
       "      <td>68</td>\n",
       "      <td>87</td>\n",
       "      <td>91</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>97</td>\n",
       "      <td>96</td>\n",
       "      <td>66</td>\n",
       "      <td>71</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>57</td>\n",
       "      <td>88</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>75</td>\n",
       "      <td>88</td>\n",
       "      <td>65</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>87</td>\n",
       "      <td>91</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>88</td>\n",
       "      <td>69</td>\n",
       "      <td>87</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>82</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>66</td>\n",
       "      <td>71</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>89</td>\n",
       "      <td>76</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>79</td>\n",
       "      <td>92</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>95</td>\n",
       "      <td>91</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>95</td>\n",
       "      <td>73</td>\n",
       "      <td>61</td>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>51</td>\n",
       "      <td>91</td>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>91</td>\n",
       "      <td>93</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "      <td>97</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>88</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>87</td>\n",
       "      <td>79</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>75</td>\n",
       "      <td>83</td>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>92</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>100</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>95</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>85</td>\n",
       "      <td>73</td>\n",
       "      <td>89</td>\n",
       "      <td>97</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>78</td>\n",
       "      <td>99</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>88</td>\n",
       "      <td>69</td>\n",
       "      <td>87</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>89</td>\n",
       "      <td>72</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>87</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>90</td>\n",
       "      <td>63</td>\n",
       "      <td>69</td>\n",
       "      <td>99</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>51</td>\n",
       "      <td>54</td>\n",
       "      <td>66</td>\n",
       "      <td>99</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>85</td>\n",
       "      <td>62</td>\n",
       "      <td>84</td>\n",
       "      <td>37</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>66</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>84</td>\n",
       "      <td>91</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>95</td>\n",
       "      <td>78</td>\n",
       "      <td>95</td>\n",
       "      <td>32</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>100</td>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>79</td>\n",
       "      <td>68</td>\n",
       "      <td>63</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>68</td>\n",
       "      <td>100</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>98</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>87</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>91</td>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>87</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     math_score  aptitude_score  science_score  logical_score  verbal_score\n",
       "9            98              99             88             71            87\n",
       "249          90              88             94             92            99\n",
       "157          97              54             62             58            66\n",
       "209          63              80             99             60            78\n",
       "75           99              90             96            100            92\n",
       "232          97              92             79             92            88\n",
       "264          89              66             80             60            77\n",
       "170          91              98             76             65            99\n",
       "42           93              94             92             77            87\n",
       "225          69              78             57             71            72\n",
       "46           71              85             93             68           100\n",
       "267          96              68             87             91            96\n",
       "143          93              68             76             80            99\n",
       "168          97              96             66             71            96\n",
       "5            93             100             57             88            72\n",
       "217          75              88             65             76            80\n",
       "230          87              91             98            100            94\n",
       "140          88              69             87             77            81\n",
       "154          89              73             85             73            84\n",
       "33           99              84             84             78            78\n",
       "109          78              69             82             64            60\n",
       "60           91              81             88             78            71\n",
       "68           90              70             85             81            60\n",
       "218          66              71             94             96            72\n",
       "56           75              82             89             76            87\n",
       "93           79              92             79             84            76\n",
       "77           95              91             80             84            63\n",
       "276          95              73             61             84            91\n",
       "273          51              91             67             58            79\n",
       "108          91              93             72             61            61\n",
       "254          85              85             92             99            86\n",
       "158          49              64             97             62            61\n",
       "167          89              94             67             69            68\n",
       "45           88              53             50             58            84\n",
       "79           87              79             89             93            68\n",
       "208          75              83             70             86            71\n",
       "66           92              86             66            100            69\n",
       "82           60              80             61             95            63\n",
       "179          85              73             89             97            73\n",
       "186          78              99             64             65            99\n",
       "30           88              69             87            100            88\n",
       "22           89              72             68             72            71\n",
       "24           87              91             90             88            95\n",
       "132          90              63             69             99            80\n",
       "73           51              54             66             99            87\n",
       "202          85              62             84             37            80\n",
       "224          85              55             74             66            71\n",
       "246          84              91             94             78            66\n",
       "90           95              78             95             32            73\n",
       "203         100              87             60             46            92\n",
       "262          79              68             63             81            72\n",
       "175          68             100             89             84            75\n",
       "92           98              73             73             87            77\n",
       "6            99              96             97             83            88\n",
       "126          89              67             86             87            87\n",
       "255          91              87             89             93            97\n",
       "271          44              64             58             87            66"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b70d0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label:  [1]\n",
      "Actual: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted label: \",model.predict(X_test_scaled[1].reshape(1,-1)))\n",
    "print(\"Actual:\",y_test.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ca391ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler1,open(\"scaler1.pkl\",'wb'))\n",
    "pickle.dump(model1,open(\"model1.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a0a36a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "# Load the scaler, label encoder, model, and class names\n",
    "scaler1 = pickle.load(open(\"scaler1.pkl\", 'rb'))\n",
    "model1 = pickle.load(open(\"model1.pkl\", 'rb'))\n",
    "class_names = ['Lawyer','Doctor','Government Officer','Artist','Finance officer',\n",
    "    'Software Engineer','Teacher','Business Owner','Scientist',\n",
    "    'Banker','Writer','Accountant','Designer','Construction Engineer',\n",
    "    'Game Developer','Stock Investor','Real Estate Developer','Programmer',\n",
    "    'Ethical hacker','ML Engineer','Data Analyst','Stock investor','Unknown']\n",
    "\n",
    "def Recommendations( math_score, aptitude_score, science_score,\n",
    "                    logical_score, verbal_score):\n",
    "    \n",
    "    \n",
    "    # Create feature array\n",
    "    feature_array = np.array([[math_score, aptitude_score, science_score,\n",
    "                    logical_score, verbal_score]])\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_features = scaler1.transform(feature_array)\n",
    "    decision_scores = model1.decision_function(scaled_features)\n",
    "    \n",
    "    # Convert decision scores to probabilities (for binary classification)\n",
    "    probabilities = expit(decision_scores)\n",
    "    \n",
    "    # Predict using the model\n",
    "    #probabilities = model1.predict_proba(scaled_features)\n",
    "    \n",
    "    # Get top five predicted classes along with their probabilities\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:3]\n",
    "    top_classes_names_probs = [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n",
    "    \n",
    "    return top_classes_names_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5020e626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Doctor\n",
      "Software Engineer\n",
      "Stock investor\n"
     ]
    }
   ],
   "source": [
    "final = Recommendations(80,90,95,96,95)\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final:\n",
    "    print(f\"{class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a98c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_score\taptitude_score\tscience_score\tlogical_score\tverbal_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334c7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b7f712bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample questions for the test\n",
    "questions = {\n",
    "    'maths': [\n",
    "        \"2*3\",\n",
    "        \"5*4\",\n",
    "        \"1*2\",\n",
    "        # ... Add more questions\n",
    "    ],\n",
    "    'aptitiude': [\n",
    "        \"If i go east and then move 90 degrees to left what direction i am facing?\",\n",
    "        \"Logical Reasoning Question 2\",\n",
    "        \"Logical Reasoning Question 3\",\n",
    "        # ... Add more questions\n",
    "    ],\n",
    "    'science': [\n",
    "        \"Science Question 1\",\n",
    "        \"Science Question 2\",\n",
    "        \"Science Question 3\",\n",
    "        # ... Add more questions\n",
    "    ],\n",
    "    'logical':[\n",
    "        \"Logical question 1\",\n",
    "        \"Logical question 2\",\n",
    "        \"logical question 3\"\n",
    "    ],\n",
    "    'verbal':[\n",
    "        'verbal question 1',\n",
    "        'verbal question 2',\n",
    "        'verbal question 3'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Sample options for the questions\n",
    "options = {\n",
    "    'maths': [\n",
    "        [\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n",
    "        [\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n",
    "        [\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n",
    "        # ... Add more options\n",
    "    ],\n",
    "    'aptitiude': [\n",
    "        [\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n",
    "        [\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n",
    "        [\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n",
    "        # ... Add more options\n",
    "    ],\n",
    "    'science': [\n",
    "        [\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n",
    "        [\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n",
    "        [\"Option 1\", \"Option 2\", \"Option 3\", \"Option 4\"],\n",
    "        # ... Add more options\n",
    "    ],\n",
    "    'logical':[\n",
    "        \"Logical option 1\",\n",
    "        \"Logical option 2\",\n",
    "        \"logical option 3\",\n",
    "        \"logical option 4\"\n",
    "    ],\n",
    "    'verbal':[\n",
    "        'verbal option 1',\n",
    "        'verbal option 2',\n",
    "        'verbal option 3',\n",
    "        'verbal option 4'\n",
    "    ]\n",
    "    \n",
    "}\n",
    "\n",
    "# Correct answers for each question (for scoring)\n",
    "answers = {\n",
    "    'maths': [1, 2, 3],  # Example: index of the correct option\n",
    "    'aptitude': [0, 2, 3],\n",
    "    'science': [1, 1, 2],\n",
    "    'logical':[1,0,2],\n",
    "    'verbal':[0,0,3]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "04e26fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'maths': 30, 'aptitude': 30, 'science': 30, 'logical': 30, 'verbal': 30}\n"
     ]
    }
   ],
   "source": [
    "# Example user answers\n",
    "user_answers = {\n",
    "    'maths': [1, 2, 3],  # Example: index of the correct option\n",
    "    'aptitude': [0, 2, 3],\n",
    "    'science': [1, 1, 2],\n",
    "    'logical': [1, 0, 2],\n",
    "    'verbal': [0, 0, 3]\n",
    "}\n",
    "\n",
    "# Example correct answers\n",
    "correct_answers = {\n",
    "    'maths': [1, 2, 3],  # Example correct answers\n",
    "    'aptitude': [0, 2, 3],\n",
    "    'science': [1, 1, 2],\n",
    "    'logical': [1, 0, 2],\n",
    "    'verbal': [0, 0, 3]\n",
    "}\n",
    "\n",
    "# Function to calculate scores\n",
    "def calculate_scores(user_answers, correct_answers):\n",
    "    scores = {}\n",
    "    for category in user_answers:\n",
    "        # Calculate the number of correct answers\n",
    "        correct_count = sum(1 for i, answer in enumerate(user_answers[category]) if answer == correct_answers[category][i])\n",
    "        # Each correct answer carries 10 points\n",
    "        scores[category] = correct_count * 10\n",
    "    return scores\n",
    "\n",
    "# Calculate and print scores\n",
    "scores = calculate_scores(user_answers, correct_answers)\n",
    "print(scores)  # Example output: {'maths': 30, 'aptitude': 30, 'science': 30, 'logical': 20, 'verbal': 30}\n",
    "feature_vector = [scores.get(category, 0) for category in ['maths', 'aptitude', 'science', 'logical', 'verbal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "29dca450",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Recommendations() missing 4 required positional arguments: 'aptitude_score', 'science_score', 'logical_score', and 'verbal_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final \u001b[38;5;241m=\u001b[39m Recommendations(calculate_scores)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop recommended studies with probabilities:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Recommendations() missing 4 required positional arguments: 'aptitude_score', 'science_score', 'logical_score', and 'verbal_score'"
     ]
    }
   ],
   "source": [
    "final = Recommendations()\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final:\n",
    "    print(f\"{class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e29ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f71928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb9ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fdfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834dd757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a3653510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Career: Business Owner\n",
      "Career: Stock Investor\n",
      "Career: Accountant\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "# Load the scaler, model, and class names\n",
    "scaler1 = pickle.load(open(\"scaler1.pkl\", 'rb'))\n",
    "model1 = pickle.load(open(\"model1.pkl\", 'rb'))\n",
    "class_names = ['Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Finance Officer',\n",
    "                'Software Engineer', 'Teacher', 'Business Owner', 'Scientist',\n",
    "                'Banker', 'Writer', 'Accountant', 'Designer', 'Construction Engineer',\n",
    "                'Game Developer', 'Stock Investor', 'Real Estate Developer', 'Programmer',\n",
    "                'Ethical Hacker', 'ML Engineer', 'Data Analyst', 'Stock Investor', 'Unknown']\n",
    "\n",
    "def calculate_scores(user_answers, correct_answers):\n",
    "    scores = {}\n",
    "    for category in user_answers:\n",
    "        correct_count = sum(1 for i, answer in enumerate(user_answers[category]) if answer == correct_answers[category][i])\n",
    "        scores[category] = correct_count * 10\n",
    "    return scores\n",
    "\n",
    "def Recommendations(math_score, aptitude_score, science_score,\n",
    "                    logical_score, verbal_score):\n",
    "    # Create feature array\n",
    "    feature_array = np.array([[math_score, aptitude_score, science_score,\n",
    "                              logical_score, verbal_score]])\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_features = scaler1.transform(feature_array)\n",
    "    decision_scores = model1.decision_function(scaled_features)\n",
    "    \n",
    "    # Convert decision scores to probabilities\n",
    "    probabilities = expit(decision_scores)\n",
    "    \n",
    "    # Get top three predicted classes along with their probabilities\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:3]\n",
    "    top_classes_names_probs = [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n",
    "    \n",
    "    return top_classes_names_probs\n",
    "\n",
    "# Example user answers\n",
    "user_answers = {\n",
    "    'maths': [1, 2, 3],\n",
    "    'aptitude': [0, 2, 3],\n",
    "    'science': [1, 1, 2],\n",
    "    'logical': [1, 0, 2],\n",
    "    'verbal': [0, 0, 3]\n",
    "}\n",
    "\n",
    "# Example correct answers\n",
    "correct_answers = {\n",
    "    'maths': [1, 2, 3],\n",
    "    'aptitude': [0, 2, 3],\n",
    "    'science': [1, 1, 2],\n",
    "    'logical': [1, 0, 2],\n",
    "    'verbal': [0, 0, 3]\n",
    "}\n",
    "\n",
    "# Calculate scores\n",
    "scores = calculate_scores(user_answers, correct_answers)\n",
    "\n",
    "# Extract scores for the recommendation function\n",
    "math_score = scores.get('maths', 0)\n",
    "aptitude_score = scores.get('aptitude', 0)\n",
    "science_score = scores.get('science', 0)\n",
    "logical_score = scores.get('logical', 0)\n",
    "verbal_score = scores.get('verbal', 0)\n",
    "\n",
    "# Get recommendations\n",
    "recommendations = Recommendations(math_score, aptitude_score, science_score, logical_score, verbal_score)\n",
    "\n",
    "# Print recommendations\n",
    "for recommendation in recommendations:\n",
    "    print(f\"Career: {recommendation[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
